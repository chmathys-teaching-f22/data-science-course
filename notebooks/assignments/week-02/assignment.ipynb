{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Science, Week 2\n",
    "\n",
    "# Predicting who will survive on the Titanic\n",
    "\n",
    "__Goal__: Brushing up Python skills and getting to know machine learning tools\n",
    "\n",
    "\n",
    "## The Titanic competition on Kaggle\n",
    "\n",
    "This is one of the continually renewed tutorial competitions on [Kaggle](https://www.kaggle.com/c/titanic). I encourage you to get a Kaggle account and try your hand at this. We'll use the same dataset for our little exercise here.\n",
    "\n",
    "## Data\n",
    "\n",
    "Your task is to create the **most generalizable** model from datasets of different sizes. \n",
    "\n",
    "We will use 3 partitions of the [Titanic](https://www.kaggle.com/c/titanic) dataset of size 100, 400, and 891. This is a fairly straightforward binary classification task with the goal of predicting *who survived* when the Titanic sank.\n",
    "\n",
    "All datasets have the following columns: \n",
    "\n",
    "| Variable | Definition                                 | Key                                            | \n",
    "|:----------|:------------------------------------------|:-----------------------------------------------|\n",
    "| Survival | Survival                                   | 0 = No, 1 = Yes                                |\n",
    "| Pclass   | Ticket class                               | 1 = 1st, 2 = 2nd, 3 = 3rd                      |\n",
    "| Sex      | Sex                                        |                                                |\n",
    "| Age      | Age in years                               |                                                |\n",
    "| Sibsp    | # of siblings / spouses aboard the Titanic |                                                |\n",
    "| Parch    | # of parents / children aboard the Titanic |                                                |\n",
    "| Ticket   | Ticket number                              |                                                |\n",
    "| Fare     | Passenger fare                             |                                                |\n",
    "| Cabin    | Cabin number                               |                                                |\n",
    "| Embarked | Port of Embarkation                        | C = Cherbourg, Q = Queenstown, S = Southampton |\n",
    "\n",
    "There are some pecularities in the data: some columns contain missing values, some are redundant, and some might only be useful with feature engineering [- what is that?].\n",
    "\n",
    "## A toy analysis - to be improved\n",
    "\n",
    "The following shows a simple example of fitting a logistic regression model to the data with 400 training examples.\n",
    "\n",
    "- Run the code and discuss ways to improve it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, matthews_corrcoef, accuracy_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"data\" # set to the name of the folder where you keep the data\n",
    "test = pd.read_csv(os.path.join(data_folder, \"test.csv\"))\n",
    "train = pd.read_csv(os.path.join(data_folder, \"train_400.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a quick look at the data\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are there missing values in the train set?\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the test set\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So - lots of missing age values. Let's fill them with the mean value of the column [- is this a good idea!?]\n",
    "train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "test[\"Age\"] = test[\"Age\"].fillna(train[\"Age\"].mean())\n",
    "\n",
    "# 1 missing Fare in test, filled with the mean\n",
    "test[\"Fare\"] = test[\"Fare\"].fillna(train[\"Fare\"].mean())\n",
    "\n",
    "# This procedure is called 'ean imputation' - can you think of (possibly) better ways to impute the missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see if it worked\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn does not like columns with  categorical values.\n",
    "# Let's make them binary dummy variables instead.\n",
    "train = pd.get_dummies(train, columns=[\"Pclass\", \"Embarked\", \"Sex\"])\n",
    "test =  pd.get_dummies(test, columns=[\"Pclass\", \"Embarked\", \"Sex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Ticket, PassengerId, Name, and Cabin column seem like they might be problematic.\n",
    "# Let's check how many unique values they contain,\n",
    "print(f\"N. of rows: {len(train)}\")\n",
    "\n",
    "for col in [\"Ticket\", \"PassengerId\", \"Name\", \"Cabin\"]:\n",
    "    print(f\"Proportion of unique values in {col}: {len(train[col].unique()) / len(train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PassengerId, Name, and Ticket are with few exceptions unique for each individual and thus unusable for predictions.\n",
    "# Cabin has a lot of missing values and a lot of unique values - so we're dropping the columns.\n",
    "\n",
    "uninformative_cols = [\"PassengerId\", \"Name\", \"Ticket\", \"Cabin\"]\n",
    "train = train.drop(columns=uninformative_cols)\n",
    "test = test.drop(columns=uninformative_cols)\n",
    "\n",
    "# Could Cabin be made informative with some feature engineering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we create a logistic regression model with the remaining columns (except the outcome 'Survived') as predictors\n",
    "model = LogisticRegression(max_iter=256)\n",
    "# Make subset of training data containing everything except the outcome\n",
    "X = train.loc[:, train.columns != \"Survived\"]\n",
    "# Make subset containing only the outcome\n",
    "Y = train[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit model on training data\n",
    "model.fit(X, Y)\n",
    "# See how well the model does on the training data\n",
    "yhat = model.predict(X)\n",
    "\n",
    "# If you get a warning, try to adjust the code so it disappears!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy on train data: {accuracy_score(Y, yhat)}\")\n",
    "confusion_matrix(Y, yhat)\n",
    "\n",
    "# Read up on the accuracy score in the sklearn documentation. What are its limitations? Which alternatives are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the model on the testing set\n",
    "X_test = test.loc[:, test.columns != \"Survived\"]\n",
    "Y_test = test[\"Survived\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = model.predict(X_test)\n",
    "print(f\"Accuracy on test data: {accuracy_score(Y_test, yhat_test)}\")\n",
    "confusion_matrix(Y_test, yhat_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvements - by you!\n",
    "\n",
    "Very much to our surprise, the toy analysis has been very impressive! Why are we surprised? We expected that we sourd fare much worse on the test set than on our training set. Was that luck or skill? Try to find out by varying your test set. Once you've done that, it's time to play around with various possible improvements of the model.\n",
    "\n",
    "__Exercises__:\n",
    "\n",
    "Discuss:\n",
    "\n",
    "- How can you get a better estimate of the out-of-sample performance?\n",
    "- How can you reduce overfitting to the training data?\n",
    "- Do you need different strategies for model creation for the different sizes of dataset?\n",
    "    - If so, what would you do differently?\n",
    "\n",
    "Code:\n",
    "\n",
    "- For each partition (i.e. each dataset) create several different models which you expect to generalize well. Evaluate them on the training sample using some form of model selection (cross-validated performance, held-out data, information criteria etc.) and choose one to test on the testing set. Your goal is to create the best-performing, most well-calibrated model, i.e. training performance should be close to testing performance (and performance should of course be high!). \n",
    "- See what performance you can get on the small datasets with clever optimization and regularization.\n",
    "\n",
    "For next time:\n",
    "\n",
    "- In your study groups, prepare a 3-5 min presentation on something interesting about your solution: Did you create some cool functions for preprocessing, test an exciting new type of model, set everything up to be run from the command line, or perhaps you're just really excited about the performance of your model. No need for slideshows, but feel free to show code.\n",
    "\n",
    "---\n",
    "\n",
    "Tips to get started:\n",
    "- Visualization can often be a good way to get started: how is the distribution of the variables? are any of them highly correlated?\n",
    "- Instead of training and testing on the whole training data, implement a form of cross-validation ([sklearn makes it easy](https://scikit-learn.org/stable/modules/cross_validation.html#computing-cross-validated-metrics))\n",
    "- Remember ridge regularization from last week? [Try it](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.RidgeClassifier.html)\n",
    "- Check out a list of models in sklearn [here](https://scikit-learn.org/stable/supervised_learning.html)\n",
    "- Lost or out of ideas? Take some inspiration from entries in the [original Kaggle challenge](https://www.kaggle.com/c/titanic/code)\n",
    "\n",
    "Things to try:\n",
    "- You might be able to get more information out of the predictors if you do some feature engineering. Perhaps add a column indicating whether the person had a cabin or not, or one calculating the family size?\n",
    "- Calculating information criteriais not entirely straight-forward in sk-learn. [This tutorial](https://machinelearningmastery.com/probabilistic-model-selection-measures/) might help\n",
    "- The outcome (survival) is not completely balanced. Over-/under-sampling might help\n",
    "- Ensemble models often generalize better than single models. Try one of the methods [here](https://scikit-learn.org/stable/modules/ensemble.html)\n",
    "- Don't feel restricted to sk-learn. Feel to make a Bayesian model in [PyMC3](https://github.com/pymc-devs/pymc3) or any other framework you want\n",
    "- High-performance interpretable models are all the rage right now. [Try one of them!](https://github.com/interpretml/interpret) \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0013076b557358abeab5cc4084611322cee179c3272f538cd180165972bc5dbc"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
